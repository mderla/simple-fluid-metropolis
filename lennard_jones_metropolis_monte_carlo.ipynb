{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the two body density while the simulation is running\n",
    "# ... increases simulation time \n",
    "COMPUTE_TWO_BODY_DENSITY = True\n",
    "\n",
    "# if set to true, notebook will dump data in XYZ format to be opened ...\n",
    "# ... in e.g. MD-viewers like Ovito\n",
    "DUMP_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking about Lennard-Jones interacting particles as having a hard core starting at the point where $u(r)=0$, then, writing down the interaction potential $$u(r)=4\\varepsilon\\left(\\frac{\\sigma}{r}\\right)^6\\left(\\left(\\frac{\\sigma}{r}\\right)^6-1\\right)$$ from which can be immediately read off, that the root lies at $r=\\sigma$. Then if there are $N$ particles in the system, the packing fraction $$\\eta=\\frac{4}{3}\\pi\\left(\\frac{\\sigma}{2}\\right)^3\\cdot N/V$$ or more generally in $d$ spatial dimensions $$\\eta=\\frac{\\pi^{d/2}}{\\Gamma\\left(\\frac{d}{2}+1\\right)}\\cdot\\left(\\frac{\\sigma}{2}\\right)^d\\cdot N/V$$ would for a system of non-overlapping particles be the fraction of the volume taken up by the particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation dimensions\n",
    "N = 50\n",
    "\n",
    "# spatial dimensions\n",
    "d = 3\n",
    "\n",
    "# box length for PBC\n",
    "box_length = 1\n",
    "\n",
    "# volume and number density\n",
    "V = box_length**d\n",
    "rho = N / V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz_snapshot_dump(filename, pos, comment='', element='H', opening_type='a'):\n",
    "\n",
    "    # File format according to https://en.wikipedia.org/wiki/XYZ_file_format\n",
    "    # <number of atoms>\n",
    "    # comment line\n",
    "    # <element> <X> <Y> <Z>\n",
    "\n",
    "    with open(filename, opening_type, encoding='ascii') as file:\n",
    "\n",
    "        # dumping number of atoms\n",
    "        file.write(str(N)+'\\n')\n",
    "\n",
    "        # comment line\n",
    "        file.write(comment+'\\n')\n",
    "        \n",
    "        # position dump\n",
    "        for i in range(N):\n",
    "            x, y, z = pos[i][0], pos[i][1], pos[i][2]\n",
    "            file.write('%s %f %f %f\\n' % (element, x, y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature given energy scale\n",
    "kBT = 1\n",
    "\n",
    "# particle diameter and Lennard-Jones energy scale in units of kBT\n",
    "eta = 0.6\n",
    "epsilon = 1 * kBT\n",
    "\n",
    "# computing sigma from packing fraction\n",
    "sigma = 2 * (gamma(1+d/2) * (eta/rho) / np.pi**(d/2))**(1/d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Œ∑ = %.2f => ùúé = %.2f, Œµ/kT = %.2f' % (eta, sigma, epsilon/kBT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction energy\n",
    "def u(r):\n",
    "    # Lennard-Jones-Potential\n",
    "    return 4*epsilon * (sigma / r)**6 * ((sigma / r)**6 - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will employ periodic boundary conditions, to create conditions as close as possible to the bulk fluid. To achieve this, two things have to be done:\n",
    "1. When computing potential energy of any given particle, this has to be done with including as many neighboring boxes as the reach of the potential requires. For Lennard-Jones it can be for all intents and purposes argued, that it's reach is about $2\\sigma$, where $\\sigma$ is chosen an order of magnitude smaller than the unit cell diameter. This way, only the immediately surrounding 26 other unit cells have to also be taken into account\n",
    "2. When updating positions, they have to be taken modulo any lattice vector $\\vec{R}=\\sum_jR^j\\vec{a}_j$ where $R^j\\in\\mathbb{Z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrounding box lattice unit vectors, ...\n",
    "# ... 26 (surrounding copies) + 1 (original)\n",
    "lattice_vectors = [\n",
    "    box_length * np.array([i,j,k])\n",
    "    for i in [-1,0,1]\n",
    "    for j in [-1,0,1]\n",
    "    for k in [-1,0,1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing the shape of the positions array\n",
    "NUM, DIM  = 0, 1\n",
    "\n",
    "# drawing random positions in a box\n",
    "positions = box_length * np.random.rand(N, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to get the Monte-Carlo Simulation into a state where it samples according to a canonical Boltzmann-distribution $$\\frac{e^{-\\beta H(\\{\\vec{x}_k,\\vec{p}_k\\})}}{Z}$$ where $H$ is total system energy, $\\beta=1/k_{\\mathrm{B}}T$ and $$Z(T)=\\int\\frac{1}{N!}\\left(\\frac{\\mathrm{d}^dx_1\\,\\mathrm{d}^dp_1}{h^d}\\right)\\cdots\\left(\\frac{\\mathrm{d}^dx_N\\,\\mathrm{d}^dp_N}{h^d}\\right)e^{-\\beta H(\\{\\vec{x}_k,\\vec{p}_k\\})}$$ with number of spatial dimensions $d$ and particle count $N$. For Hamiltonians of the form $$H(\\{\\vec{x}_k,\\vec{p}_k\\})=\\sum_k\\frac{\\vec{p}_k^2}{2m_k}+\\sum_k v(\\vec{x}_k)+\\sum_{i<j}u(|\\vec{x}_i-\\vec{x}_j|)$$ all velocities will be Maxwell-Boltzmann distributed ($v(\\vec{r})$ is the external potential, e.g. given by hard walls of some confining box). For the Boltzmann-distribution now factors into a kinetic and potential energy part, which can be seperately integrated to the two partition function factors $Z=Z_{\\mathrm{id}}Z_{\\mathrm{ex}}$ with\n",
    "\n",
    "$$Z_{\\mathrm{id}}=\\frac{1}{N!}\\prod_k\\frac{(\\lambda_{\\mathrm{th},k})^d}{V}$$\n",
    "\n",
    "$$Z_{\\mathrm{ex}}=\\int\\left(\\mathrm{d}^dx_1\\,\\frac{e^{-\\beta v(\\vec{x}_1)}}{V}\\right)\\cdots\\left(\\mathrm{d}^dx_N\\,\\frac{e^{-\\beta v(\\vec{x}_N)}}{V}\\right)\\exp\\left(-\\beta\\sum_{i<j}u(|\\vec{x}_i-\\vec{x}_j|)\\right)$$\n",
    "\n",
    "where $\\lambda_{\\mathrm{th},k}=h/\\sqrt{2\\pi\\cdot m_k\\cdot k_{\\mathrm{B}}T}$ is the thermal de-Broglie wavelength of particle $k$ (the same for all particles iff all their masses are the same) and $V$ is the effective (in general temperature dependent) volume $$V=\\int\\mathrm{d}^dr\\,e^{-\\beta v(\\vec{r})}$$ Now looking at the ensemble average of the velocity $\\vec{v}_k$ of particle $k$\n",
    "\n",
    "$$\\left\\langle\\vec{v}_k\\right\\rangle\\propto\\int\\mathrm{d}^dv_k\\exp\\left(-\\frac{\\frac{1}{2}m\\vec{v}_k^2}{k_{\\mathrm{B}}T}\\right)\\,\\vec{v}_k$$\n",
    "\n",
    "This result is arrived at by first integrating out the position dependence to a factor of $V^N\\cdot Z_{\\mathrm{ex}}$, followed by carrying out the $N-1$ momentum integrals that do not depend on $\\vec{v}_k$, only to finally cancel all of those out with factors appearing in $Z=Z_{\\mathrm{id}}Z_{\\mathrm{ex}}$. Since velocities will apparently always be Maxwell-Boltzmann distributed, the only interesting distribution to sample is the one of the spatial configurations of particles. Thus the steps drawn will be a change of system configuration, with the acceptance probability $$p_{1\\to 2}=\\min\\left(1,e^{-\\beta(\\Delta U_{1\\to 2})}\\right)$$ where $\\Delta U_{1\\to 2}$ is the change in potential energy due to changing the system configuration from $1$ to $2$.\n",
    "\n",
    "As a final remark, a motivation for the definition of $V$ (for completeness sake): for the case of a hard wall surrounding a domain $\\mathcal{D}$ in $d$-dimensional space, i.e. the external potential $$v_{\\mathrm{\\,hard\\,wall}}(\\vec{r})=\\begin{cases}\\infty&\\vec{r}\\notin\\mathcal{D}\\\\0&\\vec{r}\\in\\mathcal{D}\\end{cases}$$ the Boltzmann-factor $e^{-\\beta v(\\vec{r})}$ vanishes outside $\\mathcal{D}$ while being $1$ inside it. Thus, in the hard wall case, $V$ is exactly the volume of the domain $\\mathcal{D}$ (independent of temperature!). **Note that instead of using a hard wall**, that will add boundary effects like adsorption, I will employ **periodic boundary conditions** and will be using the unit cell volume for $V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_energy_difference_due_to_step_k(k, step_k, positions):\n",
    "    \"\"\" returns the potential energy difference (new minus old) that would occur if particle k from the configuration stored in the numpy.array positions were shifted by step_k \"\"\"\n",
    "\n",
    "    # getting old and new positions\n",
    "    old_position_k = positions[k]\n",
    "    new_position_k = old_position_k + step_k\n",
    "\n",
    "    # getting old and new potential energy ...\n",
    "    old_potential_energy = 0.0\n",
    "    new_potential_energy = 0.0\n",
    "\n",
    "    # ... by looping over every particle except for k\n",
    "    for j in range(N):\n",
    "\n",
    "        if j == k:\n",
    "            continue\n",
    "        \n",
    "        # adding j-contribution to old and new potential ...\n",
    "        # ... energy respectively for every PBC copy of ...\n",
    "        # ... particle j\n",
    "        for R in lattice_vectors:\n",
    "                \n",
    "            # current PBC copy of particle j, shifted by one of the ...\n",
    "            # ... 26 possible lattice vectors like box_length * (-1, 0, 1)\n",
    "            current_j_copy = positions[j] + R\n",
    "            \n",
    "            # old and new distance to particle j\n",
    "            r_jk_old = np.linalg.norm(current_j_copy - old_position_k)\n",
    "            r_jk_new = np.linalg.norm(current_j_copy - new_position_k)\n",
    "            \n",
    "            # adding potential energy contribution of the currently ...\n",
    "            # ... considered PBC copy of particle j\n",
    "            old_potential_energy += u(r_jk_old)\n",
    "            new_potential_energy += u(r_jk_new)\n",
    "\n",
    "    return new_potential_energy - old_potential_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_step_k(cov=sigma**2):\n",
    "    \"\"\" returns a normal-distributed d-dimensional step meant for a single particle in the Metropolis Monte Carlo simulation \"\"\"\n",
    "\n",
    "    # choosing new position from a normal distribution\n",
    "    return np.random.multivariate_normal(\n",
    "\n",
    "        # mean\n",
    "        np.zeros(d),\n",
    "\n",
    "        # covariance (diagonal with equal entries -> isotropic)\n",
    "        np.diag( cov * np.ones(d) ),\n",
    "\n",
    "        # shape\n",
    "        1\n",
    "\n",
    "    # random.multivariate_normal returns a nested ...\n",
    "    # ... result of the form [[x_1, ..., x_d]], thus ...\n",
    "    # ... calling the 0-th element of this one-element ...\n",
    "    # ... array yields the sought vector\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very important observables are the $l$-body densities $$\\rho^{(l)}(\\vec{r}_1,\\dots,\\vec{r}_l):=\\left\\langle\\sum_{j_1<\\cdots<j_l}\\delta(\\vec{r}_1-\\vec{x}_{j_1})\\cdots\\delta(\\vec{r}_1-\\vec{x}_{j_1})\\right\\rangle$$ where the sum over indices has the greater than signs in order to get every unique combination of particles exactly once. $\\rho^{(l)}$ is proportional to the probability density of finding $l$ (indistinguishable) particles exactly the positions $\\vec{r}_1,\\dots,\\vec{r}_l$. Of particular interest are the one-body density $\\rho^{(1)}(\\vec{r})=:\\rho(\\vec{r})$, which is just the molar density of the gas (which is supposed to be uniformly equal to some constant $\\rho$ in this simulation), and the two body density $\\rho^{(2)}(\\vec{r}_1,\\vec{r}_2)$, from which, in principle pressure $$P=\\rho\\,k_{\\mathrm{B}}T-\\frac {1}{6}\\int_0^\\infty 4\\pi r^2\\,\\mathrm{d}r\\cdot r\\frac{\\partial u(r)}{\\partial r}\\cdot\\rho^{(2)}(r)$$ isotermal compressibility $$k_{\\mathrm{B}}T\\frac{\\partial\\rho}{\\partial P}=1+\\int_0^\\infty 4\\pi r^2\\,\\mathrm{d}r\\,\\frac{\\rho^{(2)}(r)-\\rho^2}{\\rho}$$ energy due to particle pair interaction $$\\frac{U_{\\mathrm{ex}}}{V}=\\frac{1}{2}\\int_0^\\infty 4\\pi r^2\\,\\mathrm{d}r\\,\\rho^{(2)}(r)\\,u(r)$$ and many other density-related thermodynamic quantities can be computed. Note that in isotropic systems of isotropically interacting particles $\\rho^{(2)}$ is radially symmetric.\n",
    "\n",
    "The $l$-body densities are fields, which can for example be expanded in a practical ONB compatible with boundary conditions (say Poisson-Equation-eigenmodes for a hard-wall domain $\\mathcal{D}$ or a Fourier-Series in reciprocal basis vectors for periodic boundary conditions) which is then cut-off beyond details not resolvable due to the discrete and finite nature of the simulation. One may also\n",
    "\n",
    "1. introduce a $d$-dimensional grid of bins\n",
    "2. draw sufficiently many configurations from a $e^{-\\beta H}/Z$-distribution\n",
    "3. per drawn configuration: count, for each bin, the number of particles it contains\n",
    "\n",
    "For the radially symmetric $\\rho^{(2)}(r)$ the binning may also be introduced on the separation $r$; I will do the latter.\n",
    "\n",
    "If one wants to see $\\rho^{(2)}(r)$ up to $m$ multiplies of $\\sigma$, then one should consider: if there are $N$ particles in a $d$-dimensional box subject to periodic boundary conditions, then an upper bound as to how many particles one should expect to be able to pass before looping back to start due to the periodicity is about $N^{1/d}$ (motivated by imagining a cubic crystal of $N$ particles: the number of particles along any side will be $N^{1/d}$). The Lennard Jones fluid $\\rho^{(2)}(r)$ vanishes for $r<\\sigma$, before shooting up to a peak, after which it which oscillates with growing $r$ in a dampened manner around its $r\\to\\infty$ value of $\\rho^2$. This dampened oscillation occurs over a distance of a few $\\sigma$. If one wants to have a chance at observing for example three peaks of oscillation in three-dimensional space, then $50^{1/3}\\approx 3.68$ even leaves almost one $\\sigma$ of buffer to observe the desired effect (which, as a reminder, is finding the *bulk* fluid two-body density)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances_to_particle_k(k, positions):\n",
    "    \"\"\" Returns the distances that other particles have to particle k \"\"\"\n",
    "\n",
    "    # creating the array which will be binned afterwards\n",
    "    distances = []\n",
    "\n",
    "    # looping over every particle except for k\n",
    "    for j in range(N):\n",
    "\n",
    "        if j == k:\n",
    "            continue\n",
    "\n",
    "        # due to periodic boundary conditions, the surrounding ...\n",
    "        # ... unit cells are also included, every lattice vector ...\n",
    "        # ... shifted copy is also included. Going beyond the ...\n",
    "        # ... immediately surrounding unit cells however is ...\n",
    "        # ... will yield unphysical results due to the periodicity ...\n",
    "        # ... anyways\n",
    "        for R in lattice_vectors:\n",
    "\n",
    "            # current PBC copy of particle j, shifted by one of the ...\n",
    "            # ... 26 possible lattice vectors like box_length * (-1, 0, 1)\n",
    "            current_j_copy = positions[j] + R\n",
    "                \n",
    "            # distance between the current PBC copy of particle j ...\n",
    "            # ... and the particle k currently used as the center of ...\n",
    "            # ... the two body correlation estimator\n",
    "            r_jk = np.linalg.norm(current_j_copy - positions[k])\n",
    "\n",
    "            distances.append(r_jk)\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_body_correlation(particle_positions, sample_particle_count, r_max=N**(1/d)*sigma, bin_count=100):\n",
    "    \"\"\" randomly picks (without repetition) sample_particle_count particles, and bins all of them into a histogram \"\"\"\n",
    "\n",
    "    if sample_particle_count > N:\n",
    "        raise ValueError('sample_particle_count=%d is greater than overall particle count N=%d' % (sample_particle_count, N))\n",
    "\n",
    "    # particle indices from which the index of a sampled ...\n",
    "    # ... particle is pulled and removed\n",
    "    particle_indices = list(range(0, N))\n",
    "\n",
    "    # distances array\n",
    "    distances = []\n",
    "\n",
    "    for sample in range(sample_particle_count):\n",
    "        \n",
    "        # choosing a random particle\n",
    "        k = particle_indices.pop(np.random.randint(len(particle_indices)))\n",
    "\n",
    "        # appending distances of other particles to particle j. NOTE: The ...\n",
    "        # ... plus sign here is python's in-built list concatenation! No numpy ...\n",
    "        # ... involved \n",
    "        distances = distances + distances_to_particle_k(k, particle_positions)\n",
    "\n",
    "    # the information contained in the histogram is the number of particles ... \n",
    "    # ... found in the r-shell around particle k, i.e. rho^2 * 4*pi*r^2*dr * rho^(2)\n",
    "    histogram, r_bin_edges = np.histogram(distances, bins=bin_count, range=(0, r_max))\n",
    "    r = r_bin_edges[:-1]\n",
    "\n",
    "    # averaging the size of the bins to get a value for the shell width dr\n",
    "    dr = np.mean(np.diff(r_bin_edges))\n",
    "\n",
    "    # integrating rho^(2) yierds N * rho = N^2/V = Integral over exact ...\n",
    "    # ... distance histogram / V. Rearranging renders the following ...\n",
    "    # ... r-dependent conversion factor\n",
    "    rho_2 = (rho / sample_particle_count) * histogram / (4*np.pi*r**2*dr)\n",
    "    \n",
    "    return (r, rho_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the bin count and cutoff radius for the two body density\n",
    "r_max = N**(1/d)*sigma\n",
    "bin_count = 100\n",
    "\n",
    "# every step of the simulation, the two body density is computed by ...\n",
    "# ... randomly sampling particles from the configuration and binning ...\n",
    "# ... their distance to every other particle in the system. The ...\n",
    "# ... number of randomly (without repetion) sampled particles is ...\n",
    "# ... set here:\n",
    "sampled_particles_per_step = N\n",
    "\n",
    "# defining the distance space\n",
    "r = np.linspace(0, r_max, bin_count)\n",
    "\n",
    "# this rho_2 will contain the average measured two body density\n",
    "rho_2 = np.zeros(bin_count)\n",
    "\n",
    "# number of Metropolis Monte-Carlo steps\n",
    "step_count = 2000\n",
    "\n",
    "# burn in-time where simulation should be omitted\n",
    "burn_in_time = int(0.1 * step_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user feedback about progress\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# time resolving the acceptance rate by having a ...\n",
    "# ... string of 0 and 1, which can later be convolved ...\n",
    "# ... into a rolling average of freely choosable size\n",
    "acceptance_string = []\n",
    "\n",
    "for step in tqdm(range(step_count)):\n",
    "\n",
    "    # making every particle do a step\n",
    "    for k in range(N):\n",
    "\n",
    "        # making an isotropically drawn step of ...\n",
    "        # ... covariance (f * sigma)**2, where sigma is ...\n",
    "        # ... the diameter of the Lennard-Jones ...\n",
    "        # ... hard core { u > 0 } \n",
    "        step_k = draw_step_k(cov=(0.1*sigma)**2)\n",
    "\n",
    "        # energy difference\n",
    "        energy_difference = potential_energy_difference_due_to_step_k(k, step_k, positions)\n",
    "\n",
    "        # rolling whether to accept\n",
    "        if np.random.rand() < np.exp(-energy_difference/kBT):\n",
    "\n",
    "            # append 1 if accepted\n",
    "            acceptance_string.append(1)\n",
    "\n",
    "            # setting all positions of shifted particle ...\n",
    "            for mu in range(d):\n",
    "                # ... modulo box_length for PBC\n",
    "                positions[k][mu] = (positions[k][mu] + step_k[mu]) % box_length\n",
    "        \n",
    "        else:\n",
    "            # append 0 if rejected\n",
    "            acceptance_string.append(0)\n",
    "\n",
    "    # dumping after all particles have been looped\n",
    "    if DUMP_DATA:\n",
    "        xyz_snapshot_dump('N=%d_eta=%.1f_eps=%.1fkT.xyz' % (N, eta, epsilon), positions, comment='step %d' % step)\n",
    "\n",
    "    # computing the two body density if the burn-in ...\n",
    "    # ... is over\n",
    "    if COMPUTE_TWO_BODY_DENSITY:\n",
    "        if step >= burn_in_time:\n",
    "\n",
    "            # adding two body density of current configuration\n",
    "            r_current, rho_2_current = two_body_correlation(\n",
    "                positions,\n",
    "                sampled_particles_per_step,\n",
    "                r_max=r_max,\n",
    "                bin_count=bin_count\n",
    "            )\n",
    "\n",
    "            rho_2 = rho_2 + rho_2_current\n",
    "\n",
    "if COMPUTE_TWO_BODY_DENSITY:\n",
    "    # dividing by the number of samples\n",
    "    rho_2 = rho_2 / (step_count - burn_in_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing rolling average with ones\n",
    "kernel_size = int(step_count/2) * N\n",
    "kernel = np.ones(kernel_size) / kernel_size\n",
    "\n",
    "# local average of acceptances\n",
    "acceptance_rates = np.convolve(np.array(acceptance_string), kernel, mode='valid')\n",
    "\n",
    "# plotting the running-average of the acceptance rate over time\n",
    "plt.plot(np.array(range(acceptance_rates.size)) / N, 100*acceptance_rates, color='black')\n",
    "\n",
    "# labeling\n",
    "plt.xlabel('simulation step')\n",
    "plt.ylabel(r'acceptance rate in %')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case the two body density was computed while ...\n",
    "# ... simulating, draw it up against the low density ...\n",
    "# ... limit\n",
    "if COMPUTE_TWO_BODY_DENSITY:\n",
    "    \n",
    "    # simulation results\n",
    "    plt.plot(r/sigma, rho_2 / rho**2, color='black', linestyle='-', label=r'simulation $\\rho^{(2)}(r)$')\n",
    "    \n",
    "    # low density (i.e. second order in density) limit\n",
    "    plt.plot(r/sigma, np.exp(-u(r)/kBT), color='black', linestyle='dashed', label=r'$\\rho\\to 0$ limit $\\rho^2\\cdot e^{-\\beta u(r)}+\\mathcal{O}(\\rho^3)$')\n",
    "\n",
    "    # drawing in a line of constant one, because that is the ...\n",
    "    # ... r->infty value of rho^(2) / rho^2\n",
    "    plt.axhline(y=1, color='black', linestyle='dotted', label=r'line of $\\rho^{(2)}\\overset{!}{=}\\rho^2$')\n",
    "\n",
    "    # labeling\n",
    "    plt.xlabel(r'$r/\\sigma$')\n",
    "    plt.ylabel(r'$\\rho^{(2)}(r)\\;/\\;\\rho^2$')\n",
    "    plt.title('Structure of a Lennard-Jones (bulk) fluid taken\\nfrom a Metropolis-Monte-Carlo simulation\\n'+r'at $\\eta=%.1f$ and $\\varepsilon/k_{\\mathrm{B}}T=%.1f$' % (eta, epsilon/kBT))\n",
    "\n",
    "    # legend for the user\n",
    "    plt.legend()\n",
    "\n",
    "    # saving the figure\n",
    "    plt.savefig('LJ_two_body_density_at_N=%d_eta=%.1f_eps=%.1fkBT.pdf' % (N, eta, epsilon))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
